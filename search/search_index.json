{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Transport for London Cycling Data","text":"<p>Exploratory Data Analysis of the Transport for London (TfL) Cycling trip data.</p>"},{"location":"#overview","title":"Overview","text":"<p>The main goal is to apply the knowledge aquired during the Google Data Analytics Professional Certificate course, while keeping it simple enough to fit in the plaintext format of a github repository.</p> <p>I will analyze a single year worth of data, to limit the scope of the analysis.</p> <p>I will work with the data from 2024 since is the most recent complete year at the time of writting.</p>"},{"location":"#tools","title":"Tools","text":"<p>I will be working mainly with:</p> Tool Use DuckDB Parse, clean and query the dataset Mermaid General purpouse diagrams Seaborn Complex plots"},{"location":"analysis/","title":"Analysis","text":"<p>Now we will make a review of the main objets of the dataset:</p> <ul> <li>Trips</li> <li>Bikes</li> <li>Stations</li> <li>Routes</li> </ul> <p>We will use simple statistical visualizations to gain knowledge on the attributes value ranges, distributions, correlations and general quirks before diving into modeling the relationships with more complex analysis tools.</p>"},{"location":"analysis/bikes/","title":"Bikes","text":"<p>A total of 14920 unique bikes were used during 2024.</p> <pre><code>SELECT COUNT(DISTINCT bike_id) FROM trips;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 count(DISTINCT bike_id) \u2502\n\u2502          int64          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502          14920          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"analysis/bikes/#bike-trip-count","title":"Bike trip count","text":"<p>The trip count among all bikes shows a multi-mode distribution.</p> <p></p> <p>Possible causes:</p> <ul> <li>Location: Some bikes move between high-traffic stations.</li> <li>Age: New bikes could be added in batches mid-year.</li> </ul>"},{"location":"analysis/bikes/#bike-first-use-date","title":"Bike first use date","text":"<p>We get thefirst use date for each bike and plotting the cumulative proportion of bikes used as the year goes on.</p> <p></p> <p>We assume that a bike's first use is a good indicator of the bikes age inside the system. The bike could be new or was assigned a new ID after refurbishing.</p> <p>Here we can see that:</p> <ul> <li>most of the bikes were used in the first 2 months of the year.</li> <li>a steady amount of new bikes enters the float all-year round.</li> <li>a big increase in bikes is observed around July and October.</li> </ul>"},{"location":"analysis/bikes/#bike-age-vs-trip-count","title":"Bike age vs Trip count","text":"<p>Checking the correlation betweenn a bike's first trip date and the total trip count we observe:</p> <ul> <li>Bike Age and Trip count have an inverse relationship.</li> <li>Older bikes have a wide distribution of trip counts.</li> <li>Both observed groups of new bikes (July and October) have similar trip counts and represent 2 of the modes in the trip count distribution.</li> </ul> <p></p>"},{"location":"analysis/trips/","title":"Trips","text":""},{"location":"analysis/trips/#trip-duration","title":"Trip duration","text":"<p>Trip duration times range from a few seconds to many days. With most them falling under around 120 minutes.</p> <p></p> <p></p>"},{"location":"analysis/trips/#round-trips","title":"Round-trips","text":"<p>Flagging trips with the same start and end station as round trips reveals some insigts.</p> <p>Round trips are much less common than one-way trips.</p> <pre><code>SELECT\n  (station_end_id == station_start_id) AS round_trip,\n  COUNT(*) as count\nFROM trips_raw\nGROUP BY round_trip;\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 round_trip \u2502  count  \u2502\n\u2502  boolean   \u2502  int64  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 false      \u2502 8434689 \u2502\n\u2502 true       \u2502  320463 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p></p> <p>Closer inspection of round trips reveals a double mode.</p> <p></p> <p>Some possible causes:</p> <ul> <li>short trips:</li> <li>users changing their mind about using the bike</li> <li>users testing the app functionality and/or the bikes themselves</li> <li>users taking short trips around the block</li> <li>average trips:</li> <li>users running errands</li> <li>taking longer pleassure routes</li> </ul>"},{"location":"analysis/trips/#trips-under-1-minute","title":"Trips under 1 minute","text":"<p>There is an abundance of trips under 1 minute.</p> <p></p> <pre><code>SELECT\n  (station_end_id == station_start_id) AS round_trip,\n  COUNT(*) as count\nFROM trips_raw\nWHERE duration_ms / (1000 * 60) &lt; 1\nGROUP BY round_trip;\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 round_trip \u2502 count \u2502\n\u2502  boolean   \u2502 int64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 false      \u2502  2148 \u2502\n\u2502 true       \u2502 67117 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Removing the round trips of less than 1 minute we get a more natural distrubution.</p> <p></p> <p>Without more information it's impossible to discern the quality of the remaining 2 thousand trips records. Some posibilities:</p> <ul> <li>The two stations are really close and make it possible to get between them in less than a minute.</li> <li>Data quality issue, assigning the wrong ID to the end station.</li> </ul> <p>Going forward I will only focus on trips with durations:</p> <ul> <li>less or equal to 60 minutes</li> <li>different start and end locations if <code>duration_minutes</code> is less than 1 minute.</li> </ul> <pre><code>DELETE FROM trips\nWHERE\nduration_minutes &gt; 60\nOR\n(duration_minutes &lt; 1 AND station_start_id == station_end_id);\n</code></pre>"},{"location":"collection/","title":"Data Collection","text":"<p>Here we will describe the process to gather the dataset and make a general overview of it's structure.</p> <p>It is divided in the following steps:</p> <ul> <li>Gathering: download and merge files.</li> <li>Description: general overview of the dataset structure.</li> </ul>"},{"location":"collection/description/","title":"Data Descripton","text":""},{"location":"collection/description/#schema","title":"Schema","text":"<p>Every record in the dataset has the following fields:</p> Field Data Type Role Description Number UINT PK Record ID Start date TIMESTAMP Attribute Start of trip timestamp Start station number UINT FK Start station ID Start station STRING Attribute Name of start station End date TIMESTAMP Attribute End of trip timestamp End station number UINT FK End station ID End station STRING Attribute Name of end station Bike number UINT FK Bike ID Bike model STRING Attribute Type of bike Total duration STRING Attribute Human-readable representation of Total duration (ms) Total duration (ms) UINT Attribute Bike trip lenght in miliseconds"},{"location":"collection/gathering/","title":"Data Gathering","text":"<p>The data source is the Transport for London (TfL) Open Data, in particular, their cycling section.</p> <p>The data is published aggregating 2 weeks of data per CSV file (2 per month, 24 in a year).</p>"},{"location":"collection/gathering/#download","title":"Download","text":"<p>Opening the TfL cycling repositorty and executing the following script on the browser console will return an array with the desired 24 elements. After that, one could use many methods to actually download the CSV files.</p> <pre><code>links = $$(\"a\");\nlinks.filter((e) =&gt; e.innerText.includes(\"2024.csv\"));\n</code></pre> <p>To save disk space we compress eeach individual file using gzip.</p> <pre><code>ls data/*.csv | parallel -j 6 gzip -k {}\n</code></pre> <p>This reduces the dataset size from 1.4Gb to 300Mb.</p>"},{"location":"process/","title":"Process","text":"<p>I this section we will take a general overview of the dataset and it's entities, fix any inconsistencies and extend the original dataset with calculated fields.</p> <ul> <li>Load: Parse and merge all CSV files into a single database.</li> <li>Model: Transform the original schema to increase the analysis flexibility.</li> <li>Validate: Find and correct inconsistencies against our theory model.</li> <li>Extend: Create new attributes to facilitate working with the dataset.</li> </ul>"},{"location":"process/load/","title":"Data Loading","text":"<p>Before analysis we must join all files into a convenient format that allows us freedom to query and transform the data. The tool of choice was DuckDB.</p> <p>DuckDB allows us to:</p> <ul> <li>fast iteration while working on the CLI</li> <li>load csv data from zipped csv files</li> <li>export the data to multiple file formats such as duckdb, sqlite, csv and more.</li> <li>execute SQL queries stored in plaintext files against said database</li> </ul>"},{"location":"process/load/#attribute-renaming","title":"Attribute renaming","text":"<p>New values for the trip attributes is assigned at load time to simplify SQL query writting.</p> Original Field Name New Field Name DuckDB type Number trip_id BIGINT Start date date_start TIMESTAMP Start station number station_start_id BIGINT Start station station_start_name VARCHAR End date date_end TIMESTAMP End station number station_end_id BIGINT End station station_end_name VARCHAR Bike number bike_id BIGINT Bike model bike_model VARCHAR Total duration duration_text VARCHAR Total duration (ms) duration_ms BIGINT <p>The SQL command to create the table</p> <pre><code>-- Create target table\nCREATE TABLE trips_raw (\n    trip_id BIGINT,\n    date_start TIMESTAMP,\n    date_end TIMESTAMP,\n    station_start_id BIGINT,\n    station_end_id BIGINT,\n    station_start_name VARCHAR,\n    station_end_name VARCHAR,\n    bike_id BIGINT,\n    bike_model VARCHAR,\n    duration_text VARCHAR,\n    duration_ms BIGINT,\n);\n</code></pre>"},{"location":"process/load/#csv-formatting","title":"CSV formatting","text":"<p>There are 2 types of formatting between the 24 files, the 4 files from August and September beign the only odd ones.</p> <p>The main format:</p> <ul> <li>quotes on every field</li> <li>0-padded strings as IDs for Trips, Stations and Bikes</li> <li>Timestamp format is <code>YYYY-MM-DD HH:MM</code></li> </ul> <pre><code>\"Number\"   , \"Start date\"      , \"Start station number\", \"Start station\"                       , \"End date\"        , \"End station number\", \"End station\"                        , \"Bike number\", \"Bike model\", \"Total duration\", \"Total duration (ms)\"\n\"136666627\", \"2024-01-14 23:59\", \"001108\"              , \"North Wharf Road, Paddington\"        , \"2024-01-15 00:06\", \"003423\"            , \"Maida Vale, Maida Vale\"             , \"53020\"      , \"CLASSIC\"   , \"6m 47s\"        , \"407799\"\n\"136666625\", \"2024-01-14 23:57\", \"003447\"              , \"Gloucester Road (North), Kensington\" , \"2024-01-15 00:05\", \"001214\"            , \"Kensington Olympia Station, Olympia\", \"54559\"      , \"CLASSIC\"   , \"8m 1s\"         , \"481276\"\n</code></pre> <p>The secondary format:</p> <ul> <li>quotes only on station name fields</li> <li>non-0-padded integers as IDs for Trips, Staations and Bikes</li> <li>Timestamp format is <code>DD/MM/YYYY HH:MM</code></li> </ul> <pre><code>Number   , Start date      , Start station number, Start station                        , End date        , End station number, End station                       , Bike number, Bike model, Total duration, Total duration (ms)\n142043054, 14/08/2024 23:59,                22165, \"Fisherman's Walk West, Canary Wharf\", 15/08/2024 00:40,             200233, \"South Quay East, Canary Wharf\"   ,       59663, CLASSIC   , 40m 53s       ,             2453526\n142043055, 14/08/2024 23:59,                22159, \"Ebury Bridge, Pimlico\"              , 15/08/2024 00:04,                965, \"Tachbrook Street, Victoria\"      ,       57811, CLASSIC   , 4m 54s        ,              294201\n</code></pre>"},{"location":"process/load/#data-load","title":"Data Load","text":"<p>After accounting for the attributes data types, name aliases and timestamp formatting differences, we arrive at 2 SQL statements to load the data.</p> <p>A reduced version of the final query to load the secondary format files:</p> <pre><code>-- Load format_1 files\nINSERT INTO trips_raw\nSELECT\n    \"Number\" AS trip_id,\n    -- more lines ...\n    \"Total duration (ms)\" AS duration_ms,\nFROM read_csv(\n    'data/format_1/*.csv.gz',\n    types={\n        'Start date': TIMESTAMP,\n        -- more lines ...\n        'Bike number': BIGINT,\n    },\n    timestampformat='%d/%m/%Y %H:%M'\n);\n</code></pre>"},{"location":"process/load/#utility-attributes","title":"Utility Attributes","text":"<p>To facilitate future analysis a few new atttributes will be created.</p>"},{"location":"process/load/#route-id","title":"Route ID","text":"<p>To create a <code>route_id</code> we concatenate the 0-padded versions of the station IDs. After checking the maximun value of a station ID, 9 characters are enough to pad every value.</p> <pre><code>ALTER TABLE trips_raw\nADD COLUMN route_id VARCHAR;\n\nUPDATE trips_raw\nSET route_id = format('{:09d}{:09d}', station_start_id, station_end_id);\n</code></pre> <p>Using this scheme also ensures that the route from A to B is different from the route from B to A.</p>"},{"location":"process/load/#trip-duration-in-minutes","title":"Trip duration in minutes","text":"<p>A quick check of the <code>duration_ms</code> attribute reveals that 75% of the values fall bellow 21 minutes.</p> <pre><code>SUMMARIZE -- DuckDb utility function\nSELECT duration_ms/(1000 * 60)\nFROM trips_raw;\n\n-- Q25:  7.64 minutes\n-- Q50: 13.05 minutes\n-- Q75: 20.92 minutes\n</code></pre> <p>With this reference values I decided to add a calculated duration_minutes attribute to each record to facilitate filtering.</p> <pre><code>ALTER TABLE trips_raw\nADD COLUMN duration_minutes DOUBLE;\n\nUPDATE trips_raw\nSET duration_minutes = duration_ms/(1000 * 60);\n</code></pre>"},{"location":"process/load/#round-trip-flag","title":"Round trip flag","text":"<p>A boolean column is added to quickly filter trips that start and end in the same location.</p> <pre><code>-- Add round trip flag\nALTER TABLE trips\nADD COLUMN round_trip BOOL DEFAULT false;\n\nUPDATE trips\nSET round_trip = (station_start_id == station_end_id);\n</code></pre>"}]}