{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Transport for London Cycling Data Exploratory Data Analysis of the Transport for London (TfL) Cycling trip data. Overview The main goal is to apply the knowledge aquired during the Google Data Analytics Professional Certificate course, while keeping it simple enough to fit in the plaintext format of a github repository. I will analyze a single year worth of data, to limit the scope of the analysis. I will work with the data from 2024 since is the most recent complete year at the time of writting. Tools I will be working mainly with: Tool Use DuckDB Parse, clean and query the dataset Mermaid General purpouse diagrams Seaborn Complex plots","title":"Index"},{"location":"#transport-for-london-cycling-data","text":"Exploratory Data Analysis of the Transport for London (TfL) Cycling trip data.","title":"Transport for London Cycling Data"},{"location":"#overview","text":"The main goal is to apply the knowledge aquired during the Google Data Analytics Professional Certificate course, while keeping it simple enough to fit in the plaintext format of a github repository. I will analyze a single year worth of data, to limit the scope of the analysis. I will work with the data from 2024 since is the most recent complete year at the time of writting.","title":"Overview"},{"location":"#tools","text":"I will be working mainly with: Tool Use DuckDB Parse, clean and query the dataset Mermaid General purpouse diagrams Seaborn Complex plots","title":"Tools"},{"location":"eda/","text":"Exploratory Data Analysis Now we will make a review of the main objets of the dataset: Trips Bikes Stations Routes We will use simple statistical visualizations to gain knowledge on the attributes value ranges, distributions, correlations and general quirks before diving into modeling the relationships with more complex analysis tools.","title":"Exploratory Data Analysis"},{"location":"eda/#exploratory-data-analysis","text":"Now we will make a review of the main objets of the dataset: Trips Bikes Stations Routes We will use simple statistical visualizations to gain knowledge on the attributes value ranges, distributions, correlations and general quirks before diving into modeling the relationships with more complex analysis tools.","title":"Exploratory Data Analysis"},{"location":"eda/bikes/","text":"Bikes A total of 14920 unique bikes were used during 2024. SELECT COUNT(DISTINCT bike_id) FROM trips; \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 count(DISTINCT bike_id) \u2502 \u2502 int64 \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 14920 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Bike trip count The trip count among all bikes shows a multi-mode distribution. Possible causes: Location : Some bikes move between high-traffic stations. Age : New bikes could be added in batches mid-year. Bike first use date We get thefirst use date for each bike and plotting the cumulative proportion of bikes used as the year goes on. We assume that a bike's first use is a good indicator of the bikes age inside the system. The bike could be new or was assigned a new ID after refurbishing. Here we can see that: most of the bikes were used in the first 2 months of the year. a steady amount of new bikes enters the float all-year round. a big increase in bikes is observed around July and October. Bike age vs Trip count Checking the correlation betweenn a bike's first trip date and the total trip count we observe: Bike Age and Trip count have an inverse relationship. Older bikes have a wide distribution of trip counts. Both observed groups of new bikes (July and October) have similar trip counts and represent 2 of the modes in the trip count distribution.","title":"Bikes"},{"location":"eda/bikes/#bikes","text":"A total of 14920 unique bikes were used during 2024. SELECT COUNT(DISTINCT bike_id) FROM trips; \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 count(DISTINCT bike_id) \u2502 \u2502 int64 \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 14920 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518","title":"Bikes"},{"location":"eda/bikes/#bike-trip-count","text":"The trip count among all bikes shows a multi-mode distribution. Possible causes: Location : Some bikes move between high-traffic stations. Age : New bikes could be added in batches mid-year.","title":"Bike trip count"},{"location":"eda/bikes/#bike-first-use-date","text":"We get thefirst use date for each bike and plotting the cumulative proportion of bikes used as the year goes on. We assume that a bike's first use is a good indicator of the bikes age inside the system. The bike could be new or was assigned a new ID after refurbishing. Here we can see that: most of the bikes were used in the first 2 months of the year. a steady amount of new bikes enters the float all-year round. a big increase in bikes is observed around July and October.","title":"Bike first use date"},{"location":"eda/bikes/#bike-age-vs-trip-count","text":"Checking the correlation betweenn a bike's first trip date and the total trip count we observe: Bike Age and Trip count have an inverse relationship. Older bikes have a wide distribution of trip counts. Both observed groups of new bikes (July and October) have similar trip counts and represent 2 of the modes in the trip count distribution.","title":"Bike age vs Trip count"},{"location":"eda/trips/","text":"Trips Trip duration Trip duration times range from a few seconds to many days. With most them falling under around 120 minutes. Round-trips Flagging trips with the same start and end station as round trips reveals some insigts. Round trips are much less common than one-way trips. SELECT (station_end_id == station_start_id) AS round_trip, count(*) as count FROM trips_raw GROUP BY round_trip; \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 round_trip \u2502 count \u2502 \u2502 boolean \u2502 int64 \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 false \u2502 8434689 \u2502 \u2502 true \u2502 320463 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Closer inspection of round trips reveals a double mode. Some possible causes: short trips : users changing their mind about using the bike users testing the app functionality and/or the bikes themselves users taking short trips around the block average trips : users running errands taking longer pleassure routes Trips under 1 minute There is an abundance of trips under 1 minute. SELECT (station_end_id == station_start_id) AS round_trip, count(*) as count FROM trips_raw WHERE duration_ms / (1000 * 60) < 1 GROUP BY round_trip; \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 round_trip \u2502 count \u2502 \u2502 boolean \u2502 int64 \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 false \u2502 2148 \u2502 \u2502 true \u2502 67117 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Removing the round trips of less than 1 minute we get a more natural distrubution. Without more information it's impossible to discern the quality of the remaining 2 thousand trips records. Some posibilities: The two stations are really close and make it possible to get between them in less than a minute. Data quality issue, assigning the wrong ID to the end station. Going forward I will only focus on trips with durations: less or equal to 60 minutes different start and end locations if duration_minutes is less than 1 minute. DELETE FROM trips WHERE duration_minutes > 60 OR (duration_minutes < 1 AND station_start_id == station_end_id);","title":"Trips"},{"location":"eda/trips/#trips","text":"","title":"Trips"},{"location":"eda/trips/#trip-duration","text":"Trip duration times range from a few seconds to many days. With most them falling under around 120 minutes.","title":"Trip duration"},{"location":"eda/trips/#round-trips","text":"Flagging trips with the same start and end station as round trips reveals some insigts. Round trips are much less common than one-way trips. SELECT (station_end_id == station_start_id) AS round_trip, count(*) as count FROM trips_raw GROUP BY round_trip; \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 round_trip \u2502 count \u2502 \u2502 boolean \u2502 int64 \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 false \u2502 8434689 \u2502 \u2502 true \u2502 320463 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Closer inspection of round trips reveals a double mode. Some possible causes: short trips : users changing their mind about using the bike users testing the app functionality and/or the bikes themselves users taking short trips around the block average trips : users running errands taking longer pleassure routes","title":"Round-trips"},{"location":"eda/trips/#trips-under-1-minute","text":"There is an abundance of trips under 1 minute. SELECT (station_end_id == station_start_id) AS round_trip, count(*) as count FROM trips_raw WHERE duration_ms / (1000 * 60) < 1 GROUP BY round_trip; \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 round_trip \u2502 count \u2502 \u2502 boolean \u2502 int64 \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 false \u2502 2148 \u2502 \u2502 true \u2502 67117 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Removing the round trips of less than 1 minute we get a more natural distrubution. Without more information it's impossible to discern the quality of the remaining 2 thousand trips records. Some posibilities: The two stations are really close and make it possible to get between them in less than a minute. Data quality issue, assigning the wrong ID to the end station. Going forward I will only focus on trips with durations: less or equal to 60 minutes different start and end locations if duration_minutes is less than 1 minute. DELETE FROM trips WHERE duration_minutes > 60 OR (duration_minutes < 1 AND station_start_id == station_end_id);","title":"Trips under 1 minute"},{"location":"preparation/","text":"Data Preparation Here we will describe the process to gather, understand and preprocess the dataset before starting the analysis. It is divided in the following steps: Gathering : download and merge files. Description : general overview of the dataset. Pre Processing : initial data cleaning and augmentation.","title":"Data Preparation"},{"location":"preparation/#data-preparation","text":"Here we will describe the process to gather, understand and preprocess the dataset before starting the analysis. It is divided in the following steps: Gathering : download and merge files. Description : general overview of the dataset. Pre Processing : initial data cleaning and augmentation.","title":"Data Preparation"},{"location":"preparation/description/","text":"Data Descripton Schema Every record in the dataset has the following fields: Field Data Type Role Description Number UINT PK Record ID Start date DATETIME Attribute Start of trip timestamp Start station number VARCHAR(6) FK Start station ID Start station STRING Attribute Name of start station End date DATETIME Attribute End of trip timestamp End station number VARCHAR(6) FK End station ID End station STRING Attribute Name of end station Bike number UINT FK Bike ID Bike model STRING Attribute Type of bike Total duration STRING Attribute Human-readable representation of Total duration (ms) Total duration (ms) UINT Attribute Bike trip lenght in miliseconds","title":"Data Descripton"},{"location":"preparation/description/#data-descripton","text":"","title":"Data Descripton"},{"location":"preparation/description/#schema","text":"Every record in the dataset has the following fields: Field Data Type Role Description Number UINT PK Record ID Start date DATETIME Attribute Start of trip timestamp Start station number VARCHAR(6) FK Start station ID Start station STRING Attribute Name of start station End date DATETIME Attribute End of trip timestamp End station number VARCHAR(6) FK End station ID End station STRING Attribute Name of end station Bike number UINT FK Bike ID Bike model STRING Attribute Type of bike Total duration STRING Attribute Human-readable representation of Total duration (ms) Total duration (ms) UINT Attribute Bike trip lenght in miliseconds","title":"Schema"},{"location":"preparation/gathering/","text":"Data Gathering The data source is the Transport for London (TfL) Open Data , in particular, their cycling section . The data is published aggregating 2 weeks of data per CSV file (2 per month, 24 in a year). Download Opening the TfL cycling repositorty and executing the following script on the browser console will return an array with the desired 24 elements. After that, one could use many methods to actually download the CSV files. links = $$(\"a\"); links.filter((e) => e.innerText.includes(\"2024.csv\")); To save disk space we compress eeach individual file using gzip. ls data/*.csv | parallel -j 6 gzip -k {} This reduces the dataset size from 1.4Gb to 300Mb.","title":"Data Gathering"},{"location":"preparation/gathering/#data-gathering","text":"The data source is the Transport for London (TfL) Open Data , in particular, their cycling section . The data is published aggregating 2 weeks of data per CSV file (2 per month, 24 in a year).","title":"Data Gathering"},{"location":"preparation/gathering/#download","text":"Opening the TfL cycling repositorty and executing the following script on the browser console will return an array with the desired 24 elements. After that, one could use many methods to actually download the CSV files. links = $$(\"a\"); links.filter((e) => e.innerText.includes(\"2024.csv\")); To save disk space we compress eeach individual file using gzip. ls data/*.csv | parallel -j 6 gzip -k {} This reduces the dataset size from 1.4Gb to 300Mb.","title":"Download"},{"location":"preparation/preprocess/","text":"Data Pre Processing Before analysis we must join all files into a convenient format that allows us freedom to query and transform the data. The tool of choice was DuckDB. DuckDB allows us to: fast iteration while working on the CLI load csv data from zipped csv files export the data to multiple file formats such as duckdb, sqlite, csv and more. execute SQL queries stored in plaintext files against said database Attribute renaming New values for the trip attributes is assigned at load time to simplify SQL query writting. Original Field Name New Field Name DuckDB type Number trip_id BIGINT Start date date_start TIMESTAMP Start station number station_start_id BIGINT Start station station_start_name VARCHAR End date date_end TIMESTAMP End station number station_end_id BIGINT End station station_end_name VARCHAR Bike number bike_id BIGINT Bike model bike_model VARCHAR Total duration duration_text VARCHAR Total duration (ms) duration_ms BIGINT The SQL command to create the table -- Create target table CREATE TABLE trips_raw ( trip_id BIGINT, date_start TIMESTAMP, date_end TIMESTAMP, station_start_id BIGINT, station_end_id BIGINT, station_start_name VARCHAR, station_end_name VARCHAR, bike_id BIGINT, bike_model VARCHAR, duration_text VARCHAR, duration_ms BIGINT, ); CSV formatting There are 2 types of formatting between the 24 files, the 4 files from August and September beign the only odd ones. The main format: quotes on every field 0-padded strings as IDs for Trips, Stations and Bikes Timestamp format is YYYY-MM-DD HH:MM \"Number\" , \"Start date\" , \"Start station number\", \"Start station\" , \"End date\" , \"End station number\", \"End station\" , \"Bike number\", \"Bike model\", \"Total duration\", \"Total duration (ms)\" \"136666627\", \"2024-01-14 23:59\", \"001108\" , \"North Wharf Road, Paddington\" , \"2024-01-15 00:06\", \"003423\" , \"Maida Vale, Maida Vale\" , \"53020\" , \"CLASSIC\" , \"6m 47s\" , \"407799\" \"136666625\", \"2024-01-14 23:57\", \"003447\" , \"Gloucester Road (North), Kensington\" , \"2024-01-15 00:05\", \"001214\" , \"Kensington Olympia Station, Olympia\", \"54559\" , \"CLASSIC\" , \"8m 1s\" , \"481276\" The secondary format: quotes only on station name fields non-0-padded integers as IDs for Trips, Staations and Bikes Timestamp format is DD/MM/YYYY HH:MM Number , Start date , Start station number, Start station , End date , End station number, End station , Bike number, Bike model, Total duration, Total duration (ms) 142043054, 14/08/2024 23:59, 22165, \"Fisherman's Walk West, Canary Wharf\", 15/08/2024 00:40, 200233, \"South Quay East, Canary Wharf\" , 59663, CLASSIC , 40m 53s , 2453526 142043055, 14/08/2024 23:59, 22159, \"Ebury Bridge, Pimlico\" , 15/08/2024 00:04, 965, \"Tachbrook Street, Victoria\" , 57811, CLASSIC , 4m 54s , 294201 Data Load After accounting for the attributes data types, name aliases and timestamp formatting differences, we arrive at 2 SQL statements to load the data. A reduced version of the final query to load the secondary format files: -- Load format_1 files INSERT INTO trips_raw SELECT \"Number\" AS trip_id, ... \"Total duration (ms)\" AS duration_ms, FROM read_csv( 'data/format_1/*.csv.gz', types={ 'Start date': TIMESTAMP, ... 'Bike number': BIGINT, }, timestampformat='%d/%m/%Y %H:%M' ); Utility Attributes To facilitate future analysis a few new atttributes will be created. Route ID To create a route_id we concatenate the 0-padded versions of the station IDs. After checking the maximun value of a station ID, 9 characters are enough to pad every value. ALTER TABLE trips_raw ADD COLUMN route_id VARCHAR; UPDATE trips_raw SET route_id = format('{:09d}{:09d}', station_start_id, station_end_id); Using this scheme also ensures that the route from A to B is different from the route from B to A. Trip duration in minutes A quick check of the duration_ms attribute reveals that 75% of the values fall bellow 21 minutes. SUMMARIZE -- DuckDb utility function SELECT duration_ms/(1000 * 60) FROM trips_raw; -- Q25: 7.64 minutes -- Q50: 13.05 minutes -- Q75: 20.92 minutes With this reference values I decided to add a calculated duration_minutes attribute to each record to facilitate filtering. ALTER TABLE trips_raw ADD COLUMN duration_minutes DOUBLE; UPDATE trips_raw SET duration_minutes = duration_ms/(1000 * 60); Round trip flag A boolean column is added to quickly filter trips that start and end in the same location. -- Add round trip flag ALTER TABLE trips ADD COLUMN round_trip BOOL DEFAULT false; UPDATE trips SET round_trip = (station_start_id == station_end_id);","title":"Data Pre Processing"},{"location":"preparation/preprocess/#data-pre-processing","text":"Before analysis we must join all files into a convenient format that allows us freedom to query and transform the data. The tool of choice was DuckDB. DuckDB allows us to: fast iteration while working on the CLI load csv data from zipped csv files export the data to multiple file formats such as duckdb, sqlite, csv and more. execute SQL queries stored in plaintext files against said database","title":"Data Pre Processing"},{"location":"preparation/preprocess/#attribute-renaming","text":"New values for the trip attributes is assigned at load time to simplify SQL query writting. Original Field Name New Field Name DuckDB type Number trip_id BIGINT Start date date_start TIMESTAMP Start station number station_start_id BIGINT Start station station_start_name VARCHAR End date date_end TIMESTAMP End station number station_end_id BIGINT End station station_end_name VARCHAR Bike number bike_id BIGINT Bike model bike_model VARCHAR Total duration duration_text VARCHAR Total duration (ms) duration_ms BIGINT The SQL command to create the table -- Create target table CREATE TABLE trips_raw ( trip_id BIGINT, date_start TIMESTAMP, date_end TIMESTAMP, station_start_id BIGINT, station_end_id BIGINT, station_start_name VARCHAR, station_end_name VARCHAR, bike_id BIGINT, bike_model VARCHAR, duration_text VARCHAR, duration_ms BIGINT, );","title":"Attribute renaming"},{"location":"preparation/preprocess/#csv-formatting","text":"There are 2 types of formatting between the 24 files, the 4 files from August and September beign the only odd ones. The main format: quotes on every field 0-padded strings as IDs for Trips, Stations and Bikes Timestamp format is YYYY-MM-DD HH:MM \"Number\" , \"Start date\" , \"Start station number\", \"Start station\" , \"End date\" , \"End station number\", \"End station\" , \"Bike number\", \"Bike model\", \"Total duration\", \"Total duration (ms)\" \"136666627\", \"2024-01-14 23:59\", \"001108\" , \"North Wharf Road, Paddington\" , \"2024-01-15 00:06\", \"003423\" , \"Maida Vale, Maida Vale\" , \"53020\" , \"CLASSIC\" , \"6m 47s\" , \"407799\" \"136666625\", \"2024-01-14 23:57\", \"003447\" , \"Gloucester Road (North), Kensington\" , \"2024-01-15 00:05\", \"001214\" , \"Kensington Olympia Station, Olympia\", \"54559\" , \"CLASSIC\" , \"8m 1s\" , \"481276\" The secondary format: quotes only on station name fields non-0-padded integers as IDs for Trips, Staations and Bikes Timestamp format is DD/MM/YYYY HH:MM Number , Start date , Start station number, Start station , End date , End station number, End station , Bike number, Bike model, Total duration, Total duration (ms) 142043054, 14/08/2024 23:59, 22165, \"Fisherman's Walk West, Canary Wharf\", 15/08/2024 00:40, 200233, \"South Quay East, Canary Wharf\" , 59663, CLASSIC , 40m 53s , 2453526 142043055, 14/08/2024 23:59, 22159, \"Ebury Bridge, Pimlico\" , 15/08/2024 00:04, 965, \"Tachbrook Street, Victoria\" , 57811, CLASSIC , 4m 54s , 294201","title":"CSV formatting"},{"location":"preparation/preprocess/#data-load","text":"After accounting for the attributes data types, name aliases and timestamp formatting differences, we arrive at 2 SQL statements to load the data. A reduced version of the final query to load the secondary format files: -- Load format_1 files INSERT INTO trips_raw SELECT \"Number\" AS trip_id, ... \"Total duration (ms)\" AS duration_ms, FROM read_csv( 'data/format_1/*.csv.gz', types={ 'Start date': TIMESTAMP, ... 'Bike number': BIGINT, }, timestampformat='%d/%m/%Y %H:%M' );","title":"Data Load"},{"location":"preparation/preprocess/#utility-attributes","text":"To facilitate future analysis a few new atttributes will be created.","title":"Utility Attributes"},{"location":"preparation/preprocess/#route-id","text":"To create a route_id we concatenate the 0-padded versions of the station IDs. After checking the maximun value of a station ID, 9 characters are enough to pad every value. ALTER TABLE trips_raw ADD COLUMN route_id VARCHAR; UPDATE trips_raw SET route_id = format('{:09d}{:09d}', station_start_id, station_end_id); Using this scheme also ensures that the route from A to B is different from the route from B to A.","title":"Route ID"},{"location":"preparation/preprocess/#trip-duration-in-minutes","text":"A quick check of the duration_ms attribute reveals that 75% of the values fall bellow 21 minutes. SUMMARIZE -- DuckDb utility function SELECT duration_ms/(1000 * 60) FROM trips_raw; -- Q25: 7.64 minutes -- Q50: 13.05 minutes -- Q75: 20.92 minutes With this reference values I decided to add a calculated duration_minutes attribute to each record to facilitate filtering. ALTER TABLE trips_raw ADD COLUMN duration_minutes DOUBLE; UPDATE trips_raw SET duration_minutes = duration_ms/(1000 * 60);","title":"Trip duration in minutes"},{"location":"preparation/preprocess/#round-trip-flag","text":"A boolean column is added to quickly filter trips that start and end in the same location. -- Add round trip flag ALTER TABLE trips ADD COLUMN round_trip BOOL DEFAULT false; UPDATE trips SET round_trip = (station_start_id == station_end_id);","title":"Round trip flag"}]}